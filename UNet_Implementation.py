# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xu898cNFH4YQu3Gtow3dgAdovSIhw3Gx
"""

import torch
import torch.nn as nn

class UNet(nn.Module):
  def __init__(self):
    super(UNet, self).__init__()
    self.pool = nn.MaxPool2d(2,2)
    self.conv = nn.Conv2d(64, 3, 1)
  def Down_Conv(self, input, output):
    return nn.Conv2d(input, output, 3)
  def Up_Conv(self, input, output):
    return nn.ConvTranspose2d(input, output, 2, (2,2))
  def forward(self, x):
    x = nn.functional.relu(self.Down_Conv(3, 64)(x))
    x1 = nn.functional.relu(self.Down_Conv(64, 64)(x))
    x = self.pool(x1)
    x = nn.functional.relu(self.Down_Conv(64, 128)(x))
    x2 = nn.functional.relu(self.Down_Conv(128, 128)(x))
    x = self.pool(x2)
    x = nn.functional.relu(self.Down_Conv(128, 256)(x))
    x3 = nn.functional.relu(self.Down_Conv(256, 256)(x))
    x = self.pool(x3)
    x = nn.functional.relu(self.Down_Conv(256, 512)(x))
    x4 = nn.functional.relu(self.Down_Conv(512, 512)(x))
    x = self.pool(x4)
    x = nn.functional.relu(self.Down_Conv(512, 1024)(x))
    x = nn.functional.relu(self.Down_Conv(1024, 1024)(x))
    x = self.Up_Conv(1024, 512)(x)
    x = torch.cat((x, x4[:,:, 0:56, 0:56]), 1)
    x = nn.functional.relu(self.Down_Conv(1024, 512)(x))
    x = nn.functional.relu(self.Down_Conv(512, 512)(x))
    x = self.Up_Conv(512, 256)(x)
    x = torch.cat((x, x3[:,:, 0:104, 0:104]), 1)
    x = nn.functional.relu(self.Down_Conv(512, 256)(x))
    x = nn.functional.relu(self.Down_Conv(256, 256)(x))
    x = self.Up_Conv(256, 128)(x)
    x = torch.cat((x, x2[:, :, 0:200, 0:200]), 1)
    x = nn.functional.relu(self.Down_Conv(256, 128)(x))
    x = nn.functional.relu(self.Down_Conv(128, 128)(x))
    x = self.Up_Conv(128, 64)(x)
    x = torch.cat((x, x1[:, :, 0:392, 0:392]), 1)
    x = nn.functional.relu(self.Down_Conv(128, 64)(x))
    x = nn.functional.relu(self.Down_Conv(64, 64)(x))
    x = self.conv(x)
    return x

from PIL import Image
from torchvision.transforms import transforms
import torch.optim as optim

img = []
for i in range(1,9):
  image = Image.open("/content/drive/MyDrive/archive.zip (Unzipped Files)/Semantic segmentation dataset/Tile 1/images/image_part_00{}.jpg".format(i))
  pil2tensor = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,),(0.5,)),])
  image = pil2tensor(image)
  image = image[:,0:572,0:572]
  img.append(image)
img = torch.stack(img)

msk = []
for i in range(1,9):
  mask = Image.open("/content/drive/MyDrive/archive.zip (Unzipped Files)/Semantic segmentation dataset/Tile 1/masks/image_part_00{}.png".format(i))
  pil2tensor = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,),(0.5,)),])
  mask = pil2tensor(mask)
  mask = mask[:,0:388,0:388]
  msk.append(mask)
msk = torch.stack(msk)

net = UNet()
optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)
criterion = nn.MSELoss()
for i in range(10):
  sol = net(img)
  loss = criterion(sol, msk)
  net.zero_grad()
  loss.backward()
  optimizer.step()
  print('Loss in Iteration No.' + str(i) + ' is ' + str(loss.item()))
